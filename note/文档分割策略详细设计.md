# 文档分割策略详细设计

## 概述

本文档详细记录了RAG系统中文档分割策略的设计思路、实现细节和优化考虑。

## 分割目标

### 主要目标
1. **语义完整性**：保持内容的语义连贯性
2. **检索效率**：优化检索精度和速度
3. **上下文保持**：确保分割后的块包含足够的上下文信息
4. **元数据丰富**：为每个块提供详细的元数据

### 分割粒度选择

经过分析，选择**小节级别**作为主要分割粒度：
- **优点**：平衡了检索精度和上下文完整性
- **适用性**：适合技术文档的结构特点
- **可管理性**：块大小适中，便于处理和检索

## 分割规则详细设计

### 1. 标题层级分割

#### 标题检测规则
```python
标题层级映射：
- # 一级标题 → 章节标题
- ## 二级标题 → 小节标题
- ### 三级标题 → 子小节标题
```

#### 标题处理策略
- **遇到标题时**：创建新文档块
- **标题内容**：作为块的起始部分
- **元数据提取**：从标题中提取章节类型信息

### 2. 内容聚合规则

#### 块大小控制
```python
最小块大小: 200字符
最大块大小: 800字符
理想块大小: 300-500字符
```

#### 分割边界判断
```python
分割触发条件：
1. 字符数 >= 800
2. 遇到空行且当前块大小 >= 300
3. 遇到新标题
4. 段落自然结束
```

### 3. 特殊内容处理

#### 代码块处理
- **检测**：以 ``` 开始和结束
- **策略**：保持代码块完整，不分割
- **标记**：在元数据中标记 `has_code: true`

#### 列表项处理
- **检测**：以 -、* 或数字. 开头
- **策略**：按列表项聚合或分割
- **标记**：在元数据中标记 `has_list: true`

#### 图片引用处理
- **检测**：以 ![...] 开头
- **策略**：保留描述文本
- **处理**：不单独分割，与上下文一起

### 4. 忽略内容规则

```python
忽略的内容：
- 纯分隔线：---, ***, ___
- 空行
- 重复的标题
- 纯格式标记
```

## 元数据设计

### 基础元数据

```json
{
  "chapter_id": "07",                    // 章节编号
  "chapter_name_cn": "第一章：提示链",    // 中文章节名称
  "chapter_name_en": "Prompt Chaining",  // 英文章节名称
  "file_path": "text/07-Chapter-01-Prompt-Chaining.md",
  "file_name": "07-Chapter-01-Prompt-Chaining.md"
}
```

### 块级元数据

```json
{
  "block_index": 1,                      // 块序号
  "word_count": 350,                     // 字数统计
  "char_count": 1200,                    // 字符数统计
  "title_level": 2,                      // 标题层级
  "title": "提示链模式概述",              // 标题内容
  "section_type": "模式概述",             // 章节类型
  "has_code": false,                     // 是否包含代码
  "has_list": true,                      // 是否包含列表
  "keywords": ["提示链", "分而治之", "模块化"]  // 关键词
}
```

### 章节类型映射

```python
章节类型识别：
- "模式概述": 包含'概述'或'Overview'
- "实际应用": 包含'应用'或'Application'
- "核心要点": 包含'要点'或'Takeaway'
- "代码示例": 包含'示例'或'Example'
- "其他": 默认类型
```

## 实现细节

### 分割算法流程

```
1. 读取文档行
2. 逐行处理：
   - 检测代码块开始/结束
   - 检测标题层级
   - 判断分割条件
3. 创建文档块：
   - 生成唯一ID
   - 构建内容
   - 提取元数据
4. 质量检查：
   - 块大小验证
   - 内容有效性检查
```

### 关键词提取策略

#### 提取方法
```python
1. 文本清洗：
   - 移除代码块
   - 移除特殊字符
   - 统一空格

2. 分词处理：
   - 按空格分割
   - 过滤停用词
   - 保留中文字符和长度>=2的英文单词

3. 关键词选择：
   - 按词频排序
   - 选择前5个关键词
```

#### 停用词列表
```python
中文停用词：{'的', '了', '在', '是', '我', '有', '和', '就', '不', '人', '都', '一', '一个', '上', '也', '很', '到', '说', '要', '去', '你', '会', '着', '没有', '看', '好', '自己', '这', '那', '他', '她', '它'}
```

## 质量保证

### 分割质量指标

1. **语义完整性**：人工验证分割边界是否合理
2. **块大小分布**：统计块大小分布，确保在合理范围内
3. **内容连续性**：检查分割后内容是否保持连贯
4. **元数据准确性**：验证元数据提取的准确性

### 测试策略

#### 单元测试
```python
测试用例：
- 标题检测准确性
- 代码块处理正确性
- 块大小控制有效性
- 元数据提取完整性
```

#### 集成测试
```python
测试场景：
- 完整章节分割
- 批量文件处理
- 特殊格式文档处理
```

## 性能优化

### 处理效率

1. **批量处理**：支持多文件并行处理
2. **内存优化**：流式处理大文件
3. **缓存策略**：重复处理时使用缓存

### 存储优化

1. **压缩存储**：JSON格式压缩存储
2. **索引构建**：为元数据构建索引
3. **增量更新**：支持文档变更的增量处理

## 扩展性考虑

### 多语言支持
- 支持中英文混合内容
- 多语言关键词提取
- 国际化元数据

### 自定义分割规则
- 支持用户定义分割策略
- 可配置的块大小参数
- 灵活的特殊内容处理

### 质量评估
- 分割质量自动评估
- 用户反馈集成
- 持续优化机制

## 实际应用效果

### 测试结果

对 `07-Chapter-01-Prompt-Chaining.md` 的分割结果：
- **原始文件**：22,786 字符
- **分割块数**：79 个块
- **平均块大小**：288 字符
- **块大小分布**：大部分在 200-500 字符范围内

### 优势体现

1. **检索精度**：小块大小提高检索相关性
2. **上下文保持**：标题层级分割保持语义完整性
3. **元数据丰富**：详细的元数据支持精确过滤
4. **处理效率**：批量处理支持大规模文档集

---

*本文档将持续更新，记录分割策略的优化和改进*