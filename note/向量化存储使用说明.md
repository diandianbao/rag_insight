# 向量化存储使用说明

## 概述

本项目实现了完整的文档向量化存储功能，支持将文档分割、向量化并存储到pgvector数据库中，实现语义级别的文档检索。

## 系统要求

### 数据库
- PostgreSQL 12+
- pgvector 扩展
- 数据库名称：`hello_vector`

### 向量化服务
- Ollama 服务
- qwen3-embedding:4b 模型

### Python 依赖
```bash
pip install psycopg2-binary requests
```

## 核心模块

### 1. VectorStore (vector_store.py)

#### 主要类
- `VectorStoreConfig`: 配置类
- `DocumentChunk`: 文档块数据结构
- `PgVectorStore`: pgvector存储实现

#### 核心功能
- 数据库连接管理
- 向量化文本处理
- 文档块存储和检索
- 相似度搜索
- 系统健康检查

### 2. DocumentVectorizer (vectorize_documents.py)

#### 主要功能
- 批量处理文档文件
- 与文档分割器集成
- 进度跟踪和统计
- 错误处理

## 使用方法

### 1. 基础测试
```python
python test_vector_store.py
```

### 2. 处理项目文档
```python
python vectorize_documents.py
```

### 3. 编程方式使用

#### 初始化向量存储
```python
from vector_store import PgVectorStore, VectorStoreConfig

config = VectorStoreConfig(
    database_url="postgresql://localhost/hello_vector",
    table_name="document_chunks"
)

vector_store = PgVectorStore(config)
vector_store.connect()
vector_store.create_table()
```

#### 向量化并存储文档
```python
from document_splitter import DocumentSplitter
from vector_store import DocumentChunk

# 分割文档
splitter = DocumentSplitter()
chunks = splitter.split_document(document_content)

# 转换为向量存储格式
vector_chunks = []
for i, chunk in enumerate(chunks):
    vector_chunk = DocumentChunk(
        content=chunk.content,
        metadata=chunk.metadata,
        chunk_id=f"doc_{i}",
        document_id="document_id"
    )
    vector_chunks.append(vector_chunk)

# 批量存储
vector_store.batch_embed_and_store(vector_chunks)
```

#### 相似度搜索
```python
query = "智能体设计模式"
results = vector_store.search_similar(query, top_k=5)

for chunk in results:
    print(f"相似度: {chunk.metadata.get('similarity', 0):.4f}")
    print(f"内容: {chunk.content}")
```

## 数据库表结构

### document_chunks 表
```sql
CREATE TABLE document_chunks (
    id SERIAL PRIMARY KEY,
    chunk_id VARCHAR(255) UNIQUE NOT NULL,
    document_id VARCHAR(255) NOT NULL,
    content TEXT NOT NULL,
    metadata JSONB,
    vector VECTOR(1024),
    embedding_model VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    INDEX idx_document_id (document_id),
    INDEX idx_created_at (created_at),
    INDEX idx_vector USING ivfflat (vector vector_cosine_ops)
);
```

## 配置说明

### VectorStoreConfig 参数
- `database_url`: PostgreSQL连接字符串
- `table_name`: 向量存储表名
- `embedding_model`: 向量化模型名称
- `embedding_endpoint`: 向量化服务端点
- `vector_dimension`: 向量维度
- `batch_size`: 批量处理大小
- `timeout`: 请求超时时间

### 环境变量支持
```bash
export DATABASE_URL="postgresql://localhost/hello_vector"
export EMBEDDING_MODEL="qwen3-embedding:4b"
export EMBEDDING_ENDPOINT="http://localhost:11434/api/embeddings"
```

## 错误处理

### 异常类型
- `VectorStoreError`: 基础异常
- `EmbeddingError`: 向量化异常
- `DatabaseError`: 数据库操作异常
- `ConnectionError`: 连接异常

### 健康检查
```python
health = vector_store.health_check()
print(health)
# 输出: {'database': True, 'embedding_service': True, 'table_exists': True}
```

## 性能优化

### 批量处理
- 支持批量向量化和存储
- 可配置批量大小
- 自动错误恢复

### 索引优化
- 向量索引 (IVFFlat)
- 文档ID索引
- 时间戳索引

### 缓存策略
- 连接池管理
- 查询结果缓存（可扩展）

## 扩展性

### 多模型支持
可轻松切换不同的embedding模型：
- OpenAI embeddings
- Sentence Transformers
- 其他Ollama模型

### 多数据库支持
架构支持扩展到：
- ChromaDB
- Pinecone
- Weaviate

## 监控和统计

### 统计信息
```python
stats = vector_store.get_statistics()
print(stats)
# 输出: {
#   'total_chunks': 150,
#   'unique_documents': 25,
#   'model_distribution': {'qwen3-embedding:4b': 150},
#   'table_name': 'document_chunks'
# }
```

## 故障排除

### 常见问题

1. **数据库连接失败**
   - 检查PostgreSQL服务状态
   - 验证数据库URL格式
   - 确认pgvector扩展已安装

2. **向量化服务不可用**
   - 检查Ollama服务状态
   - 验证模型是否已下载
   - 检查网络连接

3. **向量维度不匹配**
   - 确认embedding模型输出维度
   - 更新vector_dimension配置

### 日志查看
系统使用Python标准logging模块，可通过调整日志级别获取详细信息。

## 最佳实践

1. **预处理文档**：确保文档格式正确
2. **批量处理**：使用批量操作提高效率
3. **监控资源**：定期检查数据库和向量化服务状态
4. **备份数据**：定期备份向量数据库
5. **版本控制**：记录使用的embedding模型版本

这个向量化存储系统为RAG项目提供了完整的文档处理流水线，从原始文档到语义检索的完整解决方案。